{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POVZETEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 1: uvoz podatkov, index kot timeseries, frekvnce in polnjenje manjkajočih podatkov,  risanje grafov, boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download data\n",
    "url = 'https://data.open-power-system-data.org/time_series/2018-06-30/'\n",
    "datafile = url + 'time_series_60min_singleindex.csv'\n",
    "df = pd.read_csv(datafile, index_col='utc_timestamp', parse_dates=True, low_memory=False)\n",
    "\n",
    "#ali\n",
    "opsd_daily = pd.read_csv('opsd_germany_daily.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#izvozimo v csv\n",
    "df.to_csv('data/INPUT_opsd_germany_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#za vsak stolpec nam vrne kakšnega tipa je\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretvorimo stolpec v datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#za indeks bi radi imeli čas - za index nastavimo stolpec Date\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#risanje grafov z datetime indexom . poglavje 1\n",
    "#boxplot - poglavje 1\n",
    "import plt, sns\n",
    "\n",
    "ax.plot(opsd_daily.loc[start:end, 'Solar'],\n",
    "        marker='.', \n",
    "        linestyle='-', \n",
    "        linewidth=0.5, \n",
    "        label='Daily')\n",
    "\n",
    "\n",
    "sns.boxplot(data = opsd_daily, x ='Weekday Name', y= 'Consumption')\n",
    "plt.show()\n",
    "\n",
    "#subplots doda graf na isto sliko - če želimo vse grafe na isti sliki, dodamo fig, ax = plt.subplots(), nato vse definirmao\n",
    "#in na koncu plt.show()\n",
    "\n",
    "#če želimo vsak graf posebej, damo vmes plt.show() in nato spet fig, ax = plt.subplots()\n",
    "#fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frekvence: ASFREQ\n",
    "#manjkajoče vrednosti privzeto napolne z nan, lahko pa določimo po kateri metodi naj jih napolne\n",
    "#napolnimo manjkajoče vrednosti, določimo po kateri metodi\n",
    "consum_freq['Consumption - Forward Fill'] = consum_sample.asfreq('D', method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Združevanje podatkov po obdobjih: PAZI: podatke moraš povprečit ali sumirat, če hočeš vidt podatke!\n",
    "#združiomo naše podatke po tednih in vzamemo povprečno vrednost za vsak teden: RESAMPLE\n",
    "data_columns = ['Consumption', 'Wind', 'Solar', 'Wind+Solar']\n",
    "opsd_weekly_mean = opsd_daily[data_columns].resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rolling windows\n",
    "#določimo mu število vzorcev \n",
    "opsd_7d = opsd_daily[data_columns].rolling(7, center = True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 2: kategorični podatki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pretvorba v kategorijo\n",
    "#pretvorimo stolpec v tip kategorija\n",
    "df['fruit'] = df['fruit'].astype('category')\n",
    "\n",
    "#vrednosti v kategoriji\n",
    "c = fruit_cat.values\n",
    "\n",
    "#katere kategoprije so shranjene notri\n",
    "c.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kategorične metode\n",
    "#VEDNO UPORABLJAJ .cat, KADAR UPORBLJAŠ KATEROGIČNE METODE\n",
    "\n",
    "#spreminjanje vrednosti v kategoriji\n",
    "colors = pd.Series(['periwinkle', 'mint green', 'burnt orange',\n",
    "                     'periwinkle', 'burnt orange', 'rose', \n",
    "                     'rose', 'mint green', 'rose', 'navy'])\n",
    "\n",
    "ccolors = colors.astype('category')\n",
    "\n",
    "#spremenimo  vrednost v kategoriji\n",
    "ccolors.iloc[5] = 'periwinkle'\n",
    "\n",
    "#če kategorija ne obstaja, jo moramo najprej definirati, potem lahko notri dodajamo vrednosti\n",
    "ccolors = ccolors.cat.add_categories(['a new color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRiMER:\n",
    "\n",
    "#najprej zbrišemo vse stolpce, ki imajo več kot 90% manjkajočih vrednosti\n",
    "#NAREDI KOPIJO, ne uporabljaj inplace =True!\n",
    "df = df_raw.dropna(thresh=drop_thresh, how = 'all', axis = 'columns').copy()\n",
    "\n",
    "#nato pogledamo, koliko je unique vrednosti v vsakem stolpcu\n",
    "unique_counts = pd.DataFrame.from_records([(col, df[col].nunique()) for col in df.columns],\n",
    "                                         columns=['Column_Name', 'Num_Unique'])\n",
    "\n",
    "#nato določimo mejo, do kje se splača spreminjat v kategorične vrednosti recimo 600); datumski stolpecv ne spreminjamo v kategorije\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 600 and col not in cols_to_exclude:\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 3: stringi, vektorizacija, regular exspression, manjkajoče vrednosti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#APPLY funkcija\n",
    "#fnkcija, ki vrne zadnjo besedo stringa\n",
    "def extract_last_word(element):\n",
    "    return str(element).split()[-1]\n",
    "\n",
    "#uporabimo funkcijo na celotnem stolpcu\n",
    "merged['Apply'] = merged['CurrencyUnit'].apply(extract_last_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VEKTORIZACIJA\n",
    "#funkcije, ki delujejo na celotnem stolpcu\n",
    "#vedno se uporablja z .str: Series.str.methodName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#intermezzo\n",
    "\n",
    "#value_counts privzeto ne šteje manjkajočih vrednosti\n",
    "#želimo tudi manjkajoče vrednosti: dropna = False\n",
    "lengths_apply.value_counts(dropna = False) #uporabljamo na stolpcu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#REGULAR EXSPRESSION\n",
    "import re\n",
    "\n",
    "#število naslovov, ki vsebujejo besedo python ali Python\n",
    "pattern = '[Pp]ython'\n",
    "test = hn['title'].str.contains(pattern).sum()\n",
    "\n",
    "#Naslovi, ki vsebujejo Ruby li ruby\n",
    "pattern = '[Rr]uby'\n",
    "test2 = hn[hn['title'].str.contains(pattern)]['title']\n",
    "\n",
    "#extract: poišče besedilo -- v r'' moraš napisat\n",
    "pattern = r'(\\[\\w+\\])'\n",
    "tag_5.str.extract(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MISSING DATA\n",
    "\n",
    "#1. Identifikacija manjkajoči vrednosti\n",
    "#1. Primer\n",
    "#število manjkajočih vrednosti v vsakem stolpcu v df\n",
    "happiness2016.isnull().sum()\n",
    "\n",
    "#pogledamo kje so (za  poljuben stolpec)\n",
    "missing = happiness2016['Happiness Score'].isnull()\n",
    "happiness2016[missing]\n",
    "\n",
    "#2. Primer\n",
    "#včasih happiness2016.isnull().sum() vrne same 0, kar izgleda, kot da ni manjkajočih vrednosti\n",
    "#v resnici so lahko, ampak jih moramo identificirati in pretvoriti v nan vrednosti\n",
    "#pogledamo, koliko je unique vrednosti v posameznem stolpcu in vidimo, katere vrednosti so čudne - \"manjkajoče\"\n",
    "h_2015 = happiness2015['Region'].unique()\n",
    "\n",
    "#npr. . je manjkajoča vrednost\n",
    "#preberemo csv, v katerem že definiramo, kaj so za nas manjkajoče vrednosti (nor. .)\n",
    "happiness2015 = pd.read_csv('data/wh_2015.csv', na_values='.')\n",
    "\n",
    "#lahko tudi replacamo vrednosti, ki so manjkajoče, v nan (npr ?)\n",
    "happiness2015.replace('?', np.nan,  inplace = True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#2. ko identificiramo vse manjkajoče vrednosti, je dobro pogledati, kolikšen procent je manjkajočih vrednosti\n",
    "missing_values_percent = diabetes.isnull().sum() /diabetes.shape[0] *100\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#3. vizualizacija majkajočih vrednosti\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#4. Handlanje manjkajočih vrednosti\n",
    "#1. način je, da odvržemo tiste vrstice, ki vsebujejo manjkajoče vrstice\n",
    "#zbrišemo vse vrstice, ki imajo v stolpcu Glucoze manjkajoče vrednosti\n",
    "diabetes.dropna(subset=['Glucose'], how = 'all', inplace = True)\n",
    "\n",
    "#2. način: manjkajoče vrednosti prepšemo s kakšno drugo vrednostjo \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Make a copy of diabetes\n",
    "diabetes_median = diabetes.copy(deep=True)\n",
    "# Create median imputer object\n",
    "median_imputer = SimpleImputer(strategy='median') #or straregy = 'mean' or strategy='most_frequent' or strategy='constant', fill_value=0\n",
    "# Impute median values in the DataFrame diabetes_median\n",
    "diabetes_median.iloc[:, :] = median_imputer.fit_transform(diabetes_median)\n",
    "\n",
    "#3. način: #zbrišemo stolpce, ki imajo veliko manjkajočih vrednosti\n",
    "columns_to_drop = ['LOWER CONFIDENCE INTERVAL', 'STANDARD ERROR']\n",
    "combine_dropped = combined.drop(columns= columns_to_drop, axis = 1)\n",
    "#ALI: določimo koliko je meja manjkajočih vrednosti, da vržemo ven stolpec\n",
    "combined_dropped = combine_dropped.dropna(thresh = 159, axis = 1).copy()\n",
    "\n",
    "#4. način: nafilamo manjkajoče vrednosti z vrednostmi  iz drugega dataseta\n",
    "#primer v vajah\n",
    "\n",
    "#4.1. napolnimo s povprečno vrednostjo ostalih\n",
    "cc_apps.fillna(cc_apps.mean(), inplace = True)\n",
    "\n",
    "#5. Duplicirane vrednosti\n",
    "#1. način: zbrišemo\n",
    "combine_dropped = combine_dropped.drop_duplicates(['COUNTRY', 'YEAR'])\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#5. Missing time-series data\n",
    "#narišemo graf samo za določeno obdobje\n",
    "import missingno as msno\n",
    "# Plot the sliced nullity matrix of airquality with frequency 'M'\n",
    "msno.matrix(airquality.loc['May-1976':'Jul-1976'], freq='M')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#1. način: nafilamo s prejšnjo vrednostjo:\n",
    "airquality.fillna(method = 'ffill', inplace = True) # or method='bfill'\n",
    "\n",
    "#2. način: nafilamo z interpolacijsko metodo\n",
    "linear = airquality.interpolate(method='linear',  inplace=False)[30:40])\n",
    "quadratic = airquality.interpolate(method='quadratic')\n",
    "nearest = airquality.interpolate(method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 4:SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SQLite database\n",
    "import sqlite3\n",
    "\n",
    "# Create an in memory database.\n",
    "memory = sqlite3.connect(':memory:')\n",
    "\n",
    "#povezava in branje iz baze\n",
    "conn = sqlite3.connect('data/jobs.db')\n",
    "\n",
    "#naredimo cursor; nad cursorjem potem lahko izvajamo SQL stavke\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = 'SELECT * FROM recent_grads'\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall() #OR .fetchone() OR fetchmany(5) \n",
    "    #PAZI: cursor se premika naprej vsakič dobiš naslednje rezultate\n",
    "    #Resetiramo curosor, da gre spet od začetka: cursor = cursor.execute(query)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLalchemy\n",
    "import sqlalchemy\n",
    "\n",
    "#povezava na bazo in branje\n",
    "from sqlalchemy import create_engine\n",
    "eng = create_engine('sqlite:///data/logs.db')\n",
    "\n",
    "#direkt z sqlalchemy zaženem SQL stavek\n",
    "with eng.connect() as con:\n",
    "    rs = con.execute('SELECT * FROM weblog LIMIT 5;')\n",
    "    data = rs.fetcmany(5)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baze in python\n",
    "\n",
    "#enkrat naredimo engine\n",
    "eng = create_engine('sqlite:///data/logs.db')\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#read_sql_table\n",
    "#preberemo tabelo iz baze in jo damo diretkno v data frame\n",
    "weblogs = pd.read_sql_table('weblog', eng, \n",
    "                  index_col = 'id',\n",
    "                  columns = ['id', 'status', 'method'])\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#read_sql_query\n",
    "query =\"SELECT * FROM weblog WHERE ip = '10.128.2.1' AND method = 'GET';\"\n",
    "pd.read_sql_query(query, eng)\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#to_sql\n",
    "df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
    "df.to_sql('users', con = engine, if_exists = 'append')\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#SQL data types\n",
    "from sqlalchemy.types import String, Integer\n",
    "\n",
    "dytpe_dict= {'A': Integer(),\n",
    "             'B': String(5)}\n",
    "\n",
    "df.to_sql('weblog',\n",
    "         con = engine,\n",
    "         if_exists = 'append',\n",
    "         index = False,\n",
    "         chunksize=100,\n",
    "         dtype = dtype_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 5: Procesiranje velikih datasetov v pandas-u: optimizacija tipov stolpcev,  krčenje pri branju podatkov in branje podelih (chunkih)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pogledali bomo, kako uvoziti data sete, ki so preveliki za naš pomnilnik.\n",
    "Kaj naredimo:\n",
    "    - določimo datatipe in s tem zmanjšamo prostor\n",
    "    - preberemo samo tisti del, ki nas zanima, ne celotnega dataseta\n",
    "    - obdelujemo data set po delih (npr. 1000 po 1000 vrstic)\n",
    "    - sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kako ima block manageer sestavljene objekte\n",
    "moma._data\n",
    "\n",
    "#koliko realno zavzame prostora\n",
    "moma.info(memory_usage='deep')\n",
    "\n",
    "#prikažemo brez tega, koiko zasede index\n",
    "moma.memory_usage(deep=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. OPTIMIZACIJA PO TIPIH STOLPCEV\n",
    "\n",
    "#INT/FLOAT STOLPCI: Optimizing Numeric Columns with Subtypes\n",
    "#v int lahko pretvorimo samo stolpce, ki nimajo null vrednosti\n",
    "#pretvorimo v int16\n",
    "moma['ExhibitionSortOrder'] = moma['ExhibitionSortOrder'].astype('int')\n",
    "moma['ExhibitionSortOrder'] = pd.to_numeric(moma['ExhibitionSortOrder'], downcast= 'integer')\n",
    "\n",
    "#pretvorimo float stolpce\n",
    "float_cols = moma.select_dtypes(include=['float'])\n",
    "for col in float_cols.columns: #za vsak stolpec downcastamo na float\n",
    "    moma[col] = pd.to_numeric(moma[col], downcast= 'float')\n",
    "    \n",
    "#---------------------------------------------------------------------------------------   \n",
    "#Pretvorba v DATETIME  (lahko pretvorimo, tudi če imajo NULL vrednosti)\n",
    "moma['ExhibitionBeginDate'] = pd.to_datetime(moma['ExhibitionBeginDate'], format = '%m/%d/%Y')\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#Pretvorba v kategorije (pretvorimo npr. stolpce, ki imajo več kot 50% unikatnih vrednosti)\n",
    "moma[col] = moma[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. DOLOČANJE DATA TIPOV MED BRANJEM PODATKOV\n",
    "\n",
    "#določimo, katere stolpce bi radi obdržali, določimo jim tipe, določimo, katere stolpce pretvorimo v datetime tip\n",
    "date_cols = [\"ExhibitionBeginDate\", \"ExhibitionEndDate\"]\n",
    "moma = pd.read_csv('data/MoMAExhibitions1929to1989.csv',\n",
    "                  usecols = keep_cols,\n",
    "                  parse_dates = date_cols,\n",
    "                  dtype = col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. PROCESIRANJE DATASETOV sCHUNKI\n",
    "\n",
    "#uvozimo dataset: po 250 vrstic naenkrat, izberemo samo stolpce, ki jih potrebujemo\n",
    "chunk_iter = pd.read_csv(\"data/MoMAExhibitions1929to1989.csv\", chunksize=250, \n",
    "                         dtype={\"ConstituentBeginDate\": \"float\", \"ConstituentEndDate\": \"float\"},  \n",
    "                         usecols=['ConstituentBeginDate', 'ConstituentEndDate'])\n",
    "\n",
    "#DELO s CHUNKI\n",
    "#s for zanko se sprehodimo po posameznih chunkih in appendamo listu\n",
    "overall_vc = []\n",
    "for chunk in chunk_iter:\n",
    "    chunk_vc = chunk['Gender'].value_counts()\n",
    "    overall_vc.append(chunk_vc) \n",
    "    \n",
    "#dobimo list sereiseov, ki ga z metodo concat združimo v en series\n",
    "#za vsak chunkset dobimo posebej število vrednosti\n",
    "combined_vc = pd.concat(overall_vc)\n",
    "\n",
    "#združimo z metodo group by (group by po indexu)\n",
    "final_vc = combined_vc.groupby(combined_vc.index).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. ANALIZIRANJE VELIKIH DATASETOV z SQL in PYTHONOM\n",
    "\n",
    "#po chunkih lahko shranimo vse podatke v bazo\n",
    "conn = sqlite3.connect('data/moma.db')\n",
    "moma_iter = pd.read_csv('data/moma.csv', chunksize=1000)\n",
    "\n",
    "#celoten fajl se pretvori v bazo\n",
    "for chunk in moma_iter:\n",
    "    chunk.to_sql('exhibitions', conn, \n",
    "                 if_exists='append', index=False)\n",
    "conn.close()\n",
    "\n",
    "#imamo dve možnosti: lahko izračune naredimo v SQL(izbermo samo podatke, ki jih potrebujemo)\n",
    "#ali pa izberemo celotno bazo in izračune naredimo v pythonu\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "#po chunkih lahko tudi beremo iz baze\n",
    "q = 'select exhibitionid from exhibitions;'\n",
    "chunk_iter = pd.read_sql(q, conn, chunksize=100)\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    eid_pandas_counts = eid_counts['ExhibitionID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. PRIMER:Primer analize velikega dataseta\n",
    "\n",
    "# manjkajoče vrednosti v vsakem stolpcu\n",
    "chunk_iter = pd.read_csv('data/crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1')\n",
    "\n",
    "mv_list = []\n",
    "for chunk in chunk_iter:\n",
    "    # pošičemo manjkajoče vrednosti v vsakem chunku\n",
    "    mv_list.append(chunk.isnull().sum())\n",
    "    \n",
    "# združimo s cocnact\n",
    "combine_mv_vc = pd.concat(mv_list)\n",
    "\n",
    "# group by po indexu\n",
    "combine_mv_vc_gruped = combine_mv_vc.groupby(combine_mv_vc.index).sum()\n",
    "\n",
    "# razvrstimo po vrednostih\n",
    "combine_mv_vc_gruped.sort_values()\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#shranimo v SQL po chunkih\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data/crunchbase.db')\n",
    "chunk_iter = pd.read_csv('data/crunchbase-investments.csv', \n",
    "                         chunksize=5000, \n",
    "                         encoding='ISO-8859-1')\n",
    "\n",
    "for chunk in chunk_iter:\n",
    "    chunk.to_sql('investments', conn, if_exists='append',index=False)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------     \n",
    "#prebermo, kar smo shranili\n",
    "q = 'SELECT * FROM investments LIMIT 5;'\n",
    "data_5 = pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 6: Optimizacija kode za velike datasete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.: najslabša rešitev je for zanka čez vse vrstice\n",
    "\n",
    "#2. for zanka po iterrows():\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "#3. apply \n",
    "df['distance'] = df.apply(lambda row: haversine(40.671, -73.985, row['latitude'], row['longitude']), axis = 1)\n",
    "    \n",
    "\n",
    "#VEKTORIZACIJA\n",
    "#funkciji podamo kar cel stolpec, numpy potem poskrbi za \"loopanje\"\n",
    "df['distance'] = haversine(40.671, -73.985, df['latitude'], df['longitude'])\n",
    "\n",
    "#lahko mu podamo samo values(numpy- hitreje je)\n",
    "df['distance'] = haversine(40.671, -73.985, df['latitude'].values, df['longitude'].values)\n",
    "\n",
    "#--> če že uporabljaš loopanje, uporabi vektorizacijo; najhitreje je, če uporabiš numpy objekte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PROFILIRANJE ??\n",
    "##cProfile nam pove, kateri del porabi kolko časa\n",
    "import cProfile\n",
    "profile_string = \"home_runs = calculate_runs(teams)\" #home_runs je spremenljivka v katero shranimo rezultat funkcije calculate_runs(teams)\n",
    "cProfile.run(profile_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 7:Strojno učenje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace , in $; damp v tip float; sortiramo po distance stolpcu\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings = dc_listings.sort_values(['distance'])\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#preprost machine learning model: povprečje 5 najbližjih\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x- new_listing)) #razdalja\n",
    "    temp_df = temp_df.sort_values('distance') #uredimo vrednosti\n",
    "    nearest_neighbors = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors.mean() #povprečna cena teh 5 najbližjih\n",
    "    return(predicted_price)\n",
    "\n",
    "#train in test del\n",
    "train_df = dc_listings.iloc[0:2792].copy()\n",
    "test_df = dc_listings.iloc[2792:].copy()\n",
    "\n",
    "#na testnih podatkih izračunamo ceno\n",
    "test_df['predicted_price'] = test_df['accommodates'].apply(predict_price)\n",
    "\n",
    "#NAPAKE\n",
    "test_df['error'] = np.absolute(test_df['price']- test_df['predicted_price'] )\n",
    "mae = test_df['error'].mean()\n",
    "test_df['squared_error'] = (test_df['price']- test_df['predicted_price'] )**2\n",
    "mse = test_df['squared_error'].mean()\n",
    "rmse =mse **(1/2)\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#HANDLING DATA\n",
    "#1. zbrišemo stolpce, ki so string ali, ki imajo veliko manjkajočih vrednosti\n",
    "drop_columns = ['room_type', 'city']\n",
    "dc_listings = dc_listings.drop(columns = drop_columns, axis =1)\n",
    "\n",
    "#ALI izberemo samo stolpce, ki so float in int\n",
    "data = data.select_dtypes(include=['integer', 'floating'])\n",
    "#2. zbrišemo vse vrstice, ki imajo manjkajoče vrednosti\n",
    "dc_listings = dc_listings.dropna(axis =0)\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#MODEL\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(algorithm = 'brute')\n",
    "\n",
    "# Split full dataset into train and test sets.\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "\n",
    "train_features = train_df[['accommodates', 'bathrooms']]\n",
    "train_target = train_df['price']\n",
    "knn.fit(train_features, train_target)\n",
    "predictions = knn.predict(test_df[['accommodates', 'bathrooms']])\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 8:Strojno učenje nadaljevanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LINEARNA REGRESIJA\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "cols = ['Overall Cond', 'Gr Liv Area']\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[cols], train['SalePrice'])\n",
    "\n",
    "train_predictions = lr.predict(train[cols])\n",
    "test_predictions = lr.predict(test[cols])\n",
    "#napaka\n",
    "train_mse = mean_squared_error(train_predictions, train['SalePrice'])\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "#bolj korelirane spremenljivke bodo boljše za model\n",
    "#korelacijska matrika\n",
    "corrmat = train_subset.corr()\n",
    "#zanima nas koreliranost do target stolpca\n",
    "sorted_corrs = corrmat['SalePrice'].abs().sort_values()\n",
    "\n",
    "#manjkajoče vrednosti\n",
    "#izberemo stolpce, ki imajo več kot 5% manjkajočih vrednosti -- te bomo zbrisali\n",
    "num_missing = df.isnull().sum()\n",
    "drop_missing_cols = num_missing[num_missing >len(df)/20].sort_values()\n",
    "df = df.drop(drop_missing_cols.index, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 9:Strojno učenje nadaljevanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#razdelimo na train in test del\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = credit.drop('class',axis = 1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "X = rescaledX\n",
    "\n",
    "y = credit['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#fit model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#init\n",
    "rf_model = RandomForestClassifier(random_state=2, n_estimators=10)\n",
    "\n",
    "#fit\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "rf_prediction = rf_model.predict(X_test)\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#natančnost modela\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#kot input mu podamo y_test in vrednosti, ki smo jih napovedali\n",
    "accuracy= accuracy_score(y_test, rf_prediction)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#--------------------------------------------------------------------------------------- \n",
    "#--------------------------------------------------------------------------------------- \n",
    "#funkcija GridSearchCV poišče najboljši parameter za model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': range(10, 50, 10)}\n",
    "\n",
    "#ime modela mu podamo, \n",
    "grid  = GridSearchCV(RandomForestClassifier(random_state=2), param_grid, cv = 3)\n",
    "grid_model_result = grid.fit(X,y)\n",
    "\n",
    "#rezultati\n",
    "best_score = grid_model_result.best_score_\n",
    "best_params = grid_model_result.best_params_\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------- \n",
    "#--------------------------------------------------------------------------------------- \n",
    "#--------------------------------------------------------------------------------------- \n",
    "#DEl 9: PRIMER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
